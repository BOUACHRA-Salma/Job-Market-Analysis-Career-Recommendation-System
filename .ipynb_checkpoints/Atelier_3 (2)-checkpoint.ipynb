{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h3></h3></center>\n",
    "<center><h1> <b>Atelier III : Data Cleaning</b></h1></center>\n",
    "<center><h3> Workflow Data Science</h3></center>\n",
    "<center><h3>2025 - 2026</h3></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roMLvlCJTwi6"
   },
   "source": [
    "# **Exercice I: (Handling Missing Values)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBZIz0XzO6LH"
   },
   "source": [
    "1. charger les bibliothèques et la dataset que vous utiliserez dans l'exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1V4sff-DOsBJ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Building_Permits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sf_permit\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding_Permits.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Building_Permits.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sf_permit=pd.read_csv(\"Building_Permits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaUmBeYlPmu-"
   },
   "source": [
    "2. Utilisez la cellule de code ci-dessous pour afficher les cinq premières lignes du DataFrame sf_permits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvfdZDJjRHWt"
   },
   "outputs": [],
   "source": [
    "sf_permit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFWpgndfQhAW"
   },
   "source": [
    "3. L'ensemble de données contient-il des valeurs manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_permit.isnull().sum().sum() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKWpSk6eQ-Vd"
   },
   "source": [
    "4. Quel pourcentage des valeurs de l'ensemble de données manque ? Votre réponse doit être un nombre compris entre 0 et 100. (par exemple si 1/4 des valeurs de l'ensemble de données manquent, la réponse est 25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMUvI9xUQFEu"
   },
   "outputs": [],
   "source": [
    "messing_dt=sf_permit.isnull().sum().sum()\n",
    "total_dt=np.prod(sf_permit.shape)\n",
    "pr_messing=(messing_dt/total_dt)*100\n",
    "print(\"Pourcentage des valeurs de l'ensemble de données manque: \",pr_messing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5Og7J1zSI3u"
   },
   "source": [
    "5. supprimer toutes les lignes avec des valeurs manquantes, combien de lignes reste-t-il ? (Remarque : Ne modifiez pas la valeur de sf_permits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMib8gNjSbP3"
   },
   "outputs": [],
   "source": [
    "sf_permits=sf_permit.dropna()\n",
    "lignes_rest=len(sf_permits)\n",
    "print(\"Lignes restant: \",lignes_rest)\n",
    "sf_permits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb6ZGbozSphH"
   },
   "source": [
    "6. Essayez maintenant de supprimer toutes les colonnes avec des cases vides.\n",
    "\n",
    "  * Créez un nouveau DataFrame appelé sf_permits_with_na_dropped dont toutes les colonnes avec des valeurs vides ont été supprimées.\n",
    "  * Combien de colonnes ont été supprimées du DataFrame sf_permits d'origine ? Utilisez ce nombre pour définir la valeur de la variable drop_columns ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlQhl6-zTmSJ"
   },
   "outputs": [],
   "source": [
    "sf_permits_with_na_dropped=sf_permit.dropna(axis=1)\n",
    "drop_colonne=sf_permit.shape[1]-sf_permits_with_na_dropped.shape[1]\n",
    "print(\"Nbr des colones sup: \",drop_colonne)\n",
    "sf_permits_with_na_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQyrOs5fTmfR"
   },
   "source": [
    "7. Essayez de remplacer tous les NaN dans les données sf_permits par celui qui vient directement après, puis remplacez tous les NaN par 0.\n",
    "Définissez le résultat sur un nouveau DataFrame sf_permits_with_na_imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sAebQuJQTukx"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sf_permit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sf_permits_with_na_imputed\u001b[38;5;241m=\u001b[39msf_permit\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfill\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m sf_permits_with_na_imputed\u001b[38;5;241m.\u001b[39mhead() \u001b[38;5;66;03m#remplacer tous les NaN dans les données par celui qui vient directement après\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sf_permits_with_na_imputed\u001b[38;5;241m=\u001b[39msf_permit\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sf_permit' is not defined"
     ]
    }
   ],
   "source": [
    "sf_permits_with_na_imputed=sf_permit.fillna(method='bfill',axis=0)\n",
    "sf_permits_with_na_imputed.head() #remplacer tous les NaN dans les données par celui qui vient directement après\n",
    "sf_permits_with_na_imputed=sf_permit.fillna(0)\n",
    "sf_permits_with_na_imputed.head() #remplacez tous les NaN par 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNOJ1tWpUKKn"
   },
   "source": [
    "# **Exercice II: (Scaling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFkRlyZFUU-y"
   },
   "source": [
    "Pour pratiquer la mise à l'échelle et la normalisation, nous allons utiliser un ensemble de données de campagnes Kickstarter. (Kickstarter est un site Web où les gens peuvent demander aux gens d'investir dans divers projets et produits conceptuels.)\n",
    "\n",
    "La prochaine cellule de code se charge dans les bibliothèques et la dataset que nous allons utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DcmUBc7nUUNC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# min_max scaling\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minmax_scaling\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# plotting\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Box-Cox Transformation\n",
    "from scipy import stats\n",
    "\n",
    "# min_max scaling\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "kickstarters_2017 = pd.read_csv(\"ks-projects-201801.csv\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNpi8MflWMrG"
   },
   "source": [
    "Commençons par définir les objectifs de chaque campagne, c'est-à-dire combien d'argent ils demandaient. Après mise à l'échelle, toutes les valeurs sont comprises entre 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Fxm0qZ4X6Hi"
   },
   "outputs": [],
   "source": [
    "# select the usd_goal_real column\n",
    "original_data = pd.DataFrame(kickstarters_2017.usd_goal_real)\n",
    "\n",
    "# scale the goals from 0 to 1\n",
    "scaled_data = minmax_scaling(original_data, columns=['usd_goal_real'])\n",
    "\n",
    "print('Original data\\nPreview:\\n', original_data.head())\n",
    "print('Minimum value:', float(original_data.min()),\n",
    "      '\\nMaximum value:', float(original_data.max()))\n",
    "print('_'*30)\n",
    "\n",
    "print('\\nScaled data\\nPreview:\\n', scaled_data.head())\n",
    "print('Minimum value:', float(scaled_data.min()),\n",
    "      '\\nMaximum value:', float(scaled_data.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf9v7qJyYBCS"
   },
   "source": [
    "Nous venons de mettre à l'échelle la colonne \"usd_goal_real\". maintenant vous faite la même chose pour la colonne \"goal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHGNIAMUYgyZ"
   },
   "source": [
    "1. Commencez par la création d'un DataFrame original_goal_data contenant la colonne \"goal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN-KhfG6Ym_f"
   },
   "outputs": [],
   "source": [
    "# select the usd_goal_real column\n",
    "original_goal_data = pd.DataFrame(kickstarters_2017.goal)\n",
    "\n",
    "# scale the goals from 0 to 1\n",
    "scaled_goals_data= minmax_scaling(original_goal_data, columns=['goal'])\n",
    "\n",
    "print('Original data\\nPreview:\\n', original_goal_data.head())\n",
    "print('Minimum value:', float(original_goal_data.min()),\n",
    "      '\\nMaximum value:', float(original_goal_data.max()))\n",
    "print('_'*30)\n",
    "\n",
    "print('\\nScaled data\\nPreview:\\n', scaled_goals_data.head())\n",
    "print('Minimum value:', float(scaled_goals_data.min()),\n",
    "      '\\nMaximum value:', float(scaled_goals_data.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Iw42081Yyg6"
   },
   "source": [
    "2. Utilisez original_goal_data pour créer un nouveau DataFrame scaled_goal_data avec des valeurs mises à l'échelle entre 0 et 1. Vous devez utiliser la fonction minmax_scaling()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et6MMuj4ZJ1E"
   },
   "source": [
    "# **Exercice II: (Normalisation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJlgJkBmZb4a"
   },
   "source": [
    "Vous allez maintenant pratiquer la normalisation. Nous commençons par normaliser le montant d'argent promis à chaque campagne \"usd_pledged_real\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ4l_n_eZnR6"
   },
   "outputs": [],
   "source": [
    "# get the index of all positive pledges (Box-Cox only takes positive values)\n",
    "index_of_positive_pledges = kickstarters_2017.usd_pledged_real > 0\n",
    "\n",
    "# get only positive pledges (using their indexes)\n",
    "positive_pledges = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]\n",
    "\n",
    "# normalize the pledges (w/ Box-Cox)\n",
    "normalized_pledges = pd.Series(stats.boxcox(positive_pledges)[0],\n",
    "                               name='usd_pledged_real', index=positive_pledges.index)\n",
    "\n",
    "print('Original data\\nPreview:\\n', positive_pledges.head())\n",
    "print('Minimum value:', float(positive_pledges.min()),\n",
    "      '\\nMaximum value:', float(positive_pledges.max()))\n",
    "print('_'*30)\n",
    "\n",
    "print('\\nNormalized data\\nPreview:\\n', normalized_pledges.head())\n",
    "print('Minimum value:', float(normalized_pledges.min()),\n",
    "      '\\nMaximum value:', float(normalized_pledges.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8W4dNoIaYeO"
   },
   "source": [
    "Dans la cellule de code suivante, vous allez examiner la distribution des données normalisées, où elle devrait maintenant ressembler à une distribution normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkjhIXrrZ0jR"
   },
   "outputs": [],
   "source": [
    "# plot normalized data\n",
    "ax = sns.histplot(normalized_pledges, kde=True)\n",
    "ax.set_title(\"Normalized data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUJiO6qbaNVX"
   },
   "source": [
    "Nous avons utilisé la colonne \"usd_ledged_real\". Suivez le même processus pour normaliser la colonne \"pledged\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Js6XsUShafHY"
   },
   "outputs": [],
   "source": [
    "# get the index of all positive pledges (Box-Cox only takes positive values)\n",
    "index_of_positive_pledges = kickstarters_2017.usd_pledged_real > 0\n",
    "\n",
    "# get only positive pledges (using their indexes)\n",
    "positive_pledges = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]\n",
    "\n",
    "# normalize the pledges (w/ Box-Cox)\n",
    "normalized_pledges = pd.Series(stats.boxcox(positive_pledges)[0],\n",
    "                               name='pledged', index=positive_pledges.index)\n",
    "\n",
    "print('Original data\\nPreview:\\n', positive_pledges.head())\n",
    "print('Minimum value:', float(positive_pledges.min()),\n",
    "      '\\nMaximum value:', float(positive_pledges.max()))\n",
    "print('_'*30)\n",
    "\n",
    "print('\\nNormalized data\\nPreview:\\n', normalized_pledges.head())\n",
    "print('Minimum value:', float(normalized_pledges.min()),\n",
    "      '\\nMaximum value:', float(normalized_pledges.max()))\n",
    "\n",
    "# plot normalized data\n",
    "ax = sns.histplot(normalized_pledges, kde=True)\n",
    "ax.set_title(\"Normalized data\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "roMLvlCJTwi6",
    "KNOJ1tWpUKKn",
    "Et6MMuj4ZJ1E"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
